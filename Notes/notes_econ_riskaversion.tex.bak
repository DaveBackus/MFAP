\documentclass[11pt]{article}

\input{../LaTeX/notes_template.tex}

% document starts here
\begin{document}
\parskip=\bigskipamount
\parindent=0.0in
\thispagestyle{empty}
{\large ECON-UB 233 \hfill Dave Backus @ NYU}

\bigskip\bigskip
\centerline{\Large \bf Risk \& Risk Aversion}
\centerline{Revised: \today}

\medskip
Risk and risk aversion are fundamental building blocks
for thinking about how risk is priced in markets.
We say people are {\it risk averse\/} if they
prefer a sure thing to a risky outcome with the same mean.
The question is what form this risk aversion takes.
We'll see that the entire distribution matters.
If we think about this in terms of moments and cumulants,
it's not just the variance that's relevant,
but skewness and kurtosis, too.

A quick review follows.
We start off abstractly and add more structure as we go.
Some of the early parts might be unnecessary,
but I thought looking at the issue from several different
perspectives would give us deeper insight.
We end up with what will become our workhorse:
expected utility with a power utility function.

As we work through this, keep these questions in mind.
What do we mean by risk aversion?
How can we represent it?
What kinds of risks do people dislike?
Is it the variance of outcomes, or something more?


\section{Risk}

The risk we care about is the risk of outcomes,
which we'll describe with our basic setup for random variables:
states $z$ drawn from a set $\mathcal{Z}$ and probabilities $p(z)$.
Suppose the outcome we care about is a random variable $c(z)$,
which assigns an outcome ``consumption in state $z$''
to every state $z$.
We say the outcome is riskless or riskfree if $c(z)$ is
the same for all $z$.
Otherwise, it's risky.
What kinds of risk are we concerned with?
What risks would we prefer to avoid?
That depends on our preferences, which we turn to next.


\section{Utility functions and certainty equivalents}

{\it Utility functions\/} are mathematical devices that we use
to describe the preferences of an ``economic agent,''
a hypothetical individual who follows whatever rules we lay down.
The function tells us the amount of utility (``happiness'')
the agent gets from any combination of consumption quantities.
For example, the function $U(a,b)$ might express preferences
over quantities of apples and bananas.
We assume --- always! --- that more is always better:
increasing the quantities $a$ or $b$ increases utility $U$.
Other properties of $U$ it might indicate
whether the agent prefers apples or bananas,
how many of one it takes to compensate for the loss of the other,
and so on.

We use the same tool to describe preferences
over risky consumption.
Let us say that the set of possible states is finite:
$ \mathcal{Z} = \{ 1, 2, \ldots, Z \}$.
Nothing important depends on this, but it makes the notation simpler.
The vector of possible consumption outcomes is therefore
$[c(1), c(2), \ldots, c(Z)]$.
Utility over these outcomes might be written
$U [c(1), c(2), \ldots, c(Z)]$.
Again we would say that $U$ is increasing in each of its arguments
(more is better).
Depending on other properties of $U$,
the agent might prefer to invest different amounts in
risky securities or take jobs with more or less risky income outcomes ---
any decision that involves risk.
We've done this at a high level of abstraction,
but it's helpful nonetheless to give labels to things,
even if we're somewhat vague at this point about what they mean.

[Draw indifference curve for 2-state case. What is the 45-degree line?]

One way to assess the agent's attitude toward risk
is to compare the utility of a given set of consumption outcomes
to that of a constant outcome.
The {\it certainty equivalent\/} $\mu$
is the value of constant consumption
that generates exactly the same utility:
\begin{eqnarray}
    U [c(1), c(2), \ldots, c(Z)]
            &=& U (\mu, \mu, \ldots, \mu ) .
    \label{eq:certequiv-def}
\end{eqnarray}
The idea is to think about this as an equation that (implicitly) determines $\mu$.
Given the consumption outcomes, the lhs (left-hand side) is given.
Then since the utility function $U$ is increasing in all its arguments,
we can very $\mu$ until it generates the same value.
%If we knew the function $U$, we could presumably do the calculation;
%we'll do exactly that later on once we've been more explicit about $U$.
In a sense, $\mu$ converts the utility of the risky outcome
into more handy consumption units.
Note, too, that if consumption is constant, then the certainty
equivalent equals that same constant.

[Back to 2-state case.
Show 45-degree line and certainty equivalent.]

Even at this level of generality, we can talk about risk aversion.
Consider these two objects related to a risky consumption
outcome $\{ c(z)\}$:
%
\begin{itemize}
\item The certainty equivalent $\mu$.

\item The mean consumption outcome.  The mean is
\begin{eqnarray*}
    \cbar &=& \sum_z p(z) c(z) \;\;=\;\; E(c) .
\end{eqnarray*}
\end{itemize}
So far we haven't mentioned probabilities, but we need them here to
compute the mean outcome $\cbar$.


Comparing the certainty equivalent $\mu$ and the mean outcome $\cbar$
tells us how much we dislike the risky outcome.
If $\mu = \cbar$,
then we don't care about risk at all.
Why?
Because risky consumption gives us the same
utility as constant consumption equal to $\cbar$.
%Evidently risk doesn't affect our utility in this case.
More generally, we say the agent is risk averse (dislikes risk)
if the certainty equivalent of the risky outcome
is less than the mean:   $\mu < \cbar$.
The difference between them measures how much we dislike the risky outcomes.
A concrete example of such a measure is the {\it risk penalty\/}
\begin{eqnarray}
    \rp &=& \log (\cbar/\mu)  .
    \label{eq:rp-def}
\end{eqnarray}
It tells us how much of a consumption penalty we'd be willing to accept
relative to the mean to have riskless consumption.
%It combines the amount of risk and how much we dislike it.
The log form is arbitrary, but will be convenient later on.

Here's an example.
Let's say there are two states with probabilities
$p(1) = p(2) = 1/2$.
Suppose $c(1) = 2$ and $c(2) = 8$.
Then $\cbar = 5$.
What is the certainty equivalent $\mu$?
You need to know your preferences to do this,
but let's say $\mu = 4$:  you get the same utility
from the consumption outcomes $(2,8)$ and $(4,4)$,
even though the latter gives you less, on average.
The risk penalty is therefore
$ \rp = \log (\cbar/\mu) = \log(5/4) = 0.2231$.
In words: You'd accept a 22\% reduction in average consumption to eliminate the risk.


\section{Concave and convex functions}

Here's some terminology we'll use shortly --- it comes up a lot
in economics and finance.
We say a function $f(x)$ is {\it concave\/}
if, for any two points $x_1$ and $x_2$,
a weighted average of the function at the two points
is less than the function of a weighted average of the points:
\begin{eqnarray}
    w f(x_1) + (1-w) f(x_2) &\leq& f[ w x_1 + (1-w) x_2]
    \label{eq:concave-def}
\end{eqnarray}
for any number $w$ between zero and one.
[Draw a picture, that's clearer.]
If $f$ is differentiable, that means $f''(x) < 0$.
We say $f(x)$ is  {\it convex\/}
if the inequality goes the other way.
Equivalently, $f$ is convex if $-f$ is concave.
Sometimes people use strong inequalities and distinguish
between strict and weak concavity/convexity.

{\it Examples.\/}
Which of the following are concave?  Convex?
\begin{eqnarray*}
    (a) \;\; f(x) &=& x - x^2 \\
    (b) \;\; f(x) &=& \log x  \\
    (c) \;\; f(x) &=& e^x \\
    (d) \;\; f(x) &=& x^{1-\alpha}/(1-\alpha) \\
    (e) \;\; f(x) &=& \max \{ 0, x-k \} .
    \phantom{xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx}
\end{eqnarray*}
Think about these, maybe draw them to see what they look like.
The last one you might recognize as the payoff from
a call option on $x$ with strike price $k$.


Suppose, now, that $x$ is a random variable and $f(x)$ is a function
of it.
{\it Jensen's inequality\/} says that if $f$ is concave, then
\begin{eqnarray}
    E f(x) &\leq& f [E(x)] ,
    \label{eq:jensen}
\end{eqnarray}
with equality if $x$ is constant.
If $f$ is convex, the inequality goes the other way.
You should see a parallel between
(\ref{eq:concave-def}) and (\ref{eq:jensen}), at least in the two-state case.
The difference between the left and right sides reflects
the impact of risk, so you can see that this might be
an essential tool in quantifying risk.
If $f$ is convex, the inequality goes the other way.
[Draw a concave function $f$ and show what this looks like.]

{\it Example\/}.
Suppose $x$ is normal with mean $\kappa_1$ and variance $\kappa_2$.
Then
\begin{eqnarray*}
    E \left( e^x \right) &=&  e^{\kappa_1 + \kappa_2/2}
            \;\;\geq\;\; e^{\kappa_1},
\end{eqnarray*}
with equality if $\kappa_2 = 0$ ($x$ is constant at $\mu$).
[You should ask yourself:
(i)~Where does the first relation come from?
(ii)~What does the second have to do with Jensen's inequality?]

**** Add:  mean preserving spreads.  An increase in risk lowers value of concave function.
(Raise for convex...)


\section{Expected utility with rational expectations}

Most work in economics and finance uses expected utility,
a specific form of the utility function $U$ that we'll define shortly.
We'll be no different.
But I think our long buildup is useful because it hints
that other approaches are possible.
In fact, it's an active topic of research,
both in economics and psychology.

Expected utility gives $U$ the additive form
\begin{eqnarray}
    U [c(1), c(2), \ldots, c(Z)]
            &=& \sum_z p(z) u[c(z)]  \;\;=\;\;  E [u(c)] .
\end{eqnarray}
for some state-utility function $u$.
This puts a lot of structure on preferences,
but structure is good if it's sensible,
it gives us more precise predictions.


Probabilities here are (in theory) subjective:
they're positive numbers $p(z)$ that sum to one that reflect
the agent's preferences.
We go one step further and make the assumption
of {\it rational expectations\/}:
$p(z)$ is the true probability distribution over states $z$.
There's been no end of debate about this,
but it's incredibly useful when we implement
expected utility and compare its predictions with evidence.


The action in expected utility is in the function $u$.
It controls the certainty equivalent, the solution to
\begin{eqnarray*}
    \sum_z p(z) u[c(z)]
        &=&  \sum_z p(z) u(\mu)  \;\;=\;\; u(\mu) .
\end{eqnarray*}
More on this shortly.
Clearly $u$ must be increasing (more is better):
that is, $u'(c) > 0$.
That means we can solve for the certainty equivalent:
\begin{eqnarray*}
    \mu &=& u^{-1} \left( \sum_z p(z) u[c(z)] \right)
        \;\;=\;\; u^{-1} \left[ E u(c) \right] .
\end{eqnarray*}
The expression $u^{-1}$ means the inverse function of $u$,
so that $u^{-1} [u(c)] = c $.
This is a little abstract at this point, but we'll put it to work
in the next section.


Risk aversion is more complicated.
We'll look at it a couple different ways.
Both tell us that $u$ is concave,
which here means  $u''(c) < 0$.
The first is to look at the 2-state case.
Suppose the two states occur with probability one-half each
and consumption outcomes $c(1) < c(2)$.
Mean consumption is therefore $ \cbar = (1/2)c(1) + (1/2) c(2)$.
Expected utility is
\begin{eqnarray*}
    E [u(c)] &=&  (1/2) u[c(1)] + (1/2) u[c(2)] .
\end{eqnarray*}
When is this less than $u(\cbar)$?
By Jensen's inequality, this is true if the function $u$ is concave.
So if $u'' < 0$, we have $E[u(c)] = u(\mu) < u(\cbar)$ (risk aversion).
And if we take $u^{-1}$ of both sides, we have
$\mu < \cbar$.

[As usual, it's easier if you draw a picture.
Plot $u(c)$ v $c$.
Show expected utility and certainty equivalent.]

So we've seen that a concave function $u$ implies risk aversion.
We get a sharper sense of what properties of $u$ matter with
a Taylor series expansion,
a trick devised by Paul Samuelson.
Recall that the Taylor series expansion (if it exists) of a
function $f$ of a variable $x$ around the point $x^*$ is
\begin{eqnarray*}
    f(x) &=& f(x^*) + f'(x^*) (x-x^*) + f''(x^*) (x-x^*)^2/2 +
        f'''(x^*) (x-x^*)^3/3! + \cdots .
\end{eqnarray*}
The Taylor series expansion of $u$ around mean consumption $\cbar$
is
\begin{eqnarray*}
    u(c) &=& u(\cbar) + u'(\cbar) (c-\cbar)  + u''(\cbar) (c-\cbar)^2/2
        + u'''(\cbar) (c-\cbar)^3/3! + \cdots .
\end{eqnarray*}
Expected utility is therefore
\begin{eqnarray}
  E u(c) &=& u(\cbar) + u''(\cbar) E (c-\cbar)^2/2
        + u'''(\cbar) E (c-\cbar)^3/3! + \cdots \nonumber \\
        &=& u(\cbar) + u''(\cbar) \mu_2/2
            + u'''(\cbar) \mu_3 /3! + u''''(\cbar) \mu_4 /4! + \cdots ,
        \label{eq:eu-samuelson}
\end{eqnarray}
where $\mu_j$ is the $j$th central moment of the consumption outcome $c$.
We'll refer to this as the Samuelson expansion.
Note that the linear term disappears.
It's sometimes said that expected utility agents
don't care about small risks, because if the risks are small enough
the other terms go to zero and $u(c) \approx u(\cbar)$.
Note too that increasing the variance reduces
utility since $u'' < 0$,
so variance is evidently a disliked component of risk.
What about skewness or kurtosis, captured here by the third
and fourth central moments, $\mu_3$ and $\mu_4$?
The answer depends, apparently,
on the third and fourth derivatives of $u$,
whatever those might be.


\section{Power utility}

Since we have a practical applied interest in this subject,
we'd like to have a specific function we can put to work.
That function is the power function;
applied to utility we would write
\begin{eqnarray*}
    u(c) &=& c^{1-\alpha}/(1-\alpha)
\end{eqnarray*}
for some parameter $\alpha > 0$.
The parameter $\alpha$ controls sensitivity to risks of all kinds
and is often referred to (for reasons we won't go into)
as the {\it coefficient of relative risk aversion\/}.
Larger values of $\alpha$ are associated with stronger aversion to risk.
A small technical point:  with this utility function,
and most others we'll use in this class,
we'll restrict consumption $c$ to be positive.

What about its derivatives?
The first two are
\begin{eqnarray*}
    u'(c)  &=& c^{-\alpha} \;\;>\;\; 0 \\
    u''(c) &=& -\alpha c^{-\alpha-1} \;\;<\;\; 0 ,
\end{eqnarray*}
which have the signs we want.
The third and fourth derivatives are
\begin{eqnarray*}
    u'''(c)  &=& \alpha (\alpha+1) c^{-\alpha-2} \;\;>\;\; 0 \\
    u''''(c) &=& - \alpha (\alpha+1) (\alpha+2) c^{-\alpha-2} \;\;<\;\; 0 .
\end{eqnarray*}
The Samuelson expansion (\ref{eq:eu-samuelson}) tells us then that
power expected utility agents like positive skewness
and dislike positive kurtosis.
[Can you think of examples?]

With power utility,
the certainty equivalent is
\begin{eqnarray}
    \mu &=& \left( \sum_z p(z) c(z)^{1-\alpha} \right)^{1/(1-\alpha)}
        \;\;=\;\; \left[ E (c^{1-\alpha}) \right]^{1/(1-\alpha)} .
    \label{eq:certainty-equivalent-power}
\end{eqnarray}
[If that's not clear, go back to the previous versions.]
It's a little ugly, but at least we have a formula we can use ---
and we'll do that right now.


One question we might ask ourselves is what values of $\alpha$ are reasonable.
That's a tough question,
but a useful starting point is to consider an example and apply introspection.
Suppose you are given two choices for your career income, with the same
income every year:
\begin{itemize}
\item Choice 1:  probability one-half each of an income (= consumption)
of 100k a year or 200k a year.
\item Choice 2:  a sure income (= consumption) of $\mu$ (your certainty equivalent).
\end{itemize}
The question for you (here's where introspection comes in) is:
What value of $\mu$ generates the same utility as Choice 1?
Given an answer, we can reverse engineer your risk aversion
parameter $\alpha$.

Here's a Matlab script that does the calculation:
\begin{verbatim}
% inputs
c = [100; 200];
p = [1/2; 1/2];
% introspective estimate of your certainty equivalent
mu = 125
% vary alpha until you hit your certainty equivalent
alpha = 2
mu_guess = sum(p.*c.^(1-alpha))^(1/(1-alpha))
\end{verbatim}
The idea is to keep guessing $\alpha$ until you match your value of $\mu$.
If your certainty equivalent is $\mu = 125$, then
your implied value of $\alpha$ is about 3.25.
You can figure this out by trying different values of $\alpha$
until you find one that gives you the same certainty equivalent.
Or you could do this for a bunch of values of $\alpha$ at the same time
(think of $\alpha$ as a grid)
using Matlab's vector capabilities.
Or you could use a numerical equation-solver,
which we'll do later in the course.


\section{Cumulant expansion of risk penalties}

Here's another take on how we respond to various kinds of risks:
we examine the impact of cumulants on the risk penalty (\ref{eq:rp-def}).
We'll use the  mgf and (especially) the cgf of $\log c$.
Let us say, to be concrete,
that $x = \log c$ has mgf $h(s) = E (e^{sx})$ and cgf $k(s) = \log h(s) = \log E (e^{sx}) $.

The first ingredient of the risk penalty is mean consumption:
$\cbar = E(c) = E (e^x) = h(1) = \exp[k(1)]$.
[Are you with me?]

The second ingredient is the certainty equivalent.
Expected utility is connected to the mgf and cgf by
\begin{eqnarray*}
    E (c^{1-\alpha})/(1-\alpha) &=& E (e^{(1-\alpha) x})/(1-\alpha) \\
        &=&  h(1-\alpha)/(1-\alpha) \;\;=\;\; \exp[k(1-\alpha)]/(1-\alpha)
\end{eqnarray*}
The certainty equivalent follows from equating expected utility to the utility
of constant consumption equal to $\mu$:
\begin{eqnarray*}
    u (\mu) \;\;=\;\; \mu^{1-\alpha}/(1-\alpha)
            &=& E [u(c)]  \\
            &=& E \big( c^{1-\alpha} \big)/(1-\alpha)
                    \;\;=\;\; E \Big( e^{(1-\alpha) \log c} \Big)/(1-\alpha) \\
            &=& h(1-\alpha)/(1-\alpha) \;\;=\;\; \exp[k(1-\alpha)]/(1-\alpha) .
\end{eqnarray*}
That gives us
\begin{eqnarray*}
    \mu^{1-\alpha} &=& h(1-\alpha) \;\;=\;\; \exp[k(1-\alpha)] \\
    \Rightarrow \;\; \mu &=&  h(1-\alpha)^{1/(1-\alpha)} \;\;=\;\; \exp[k(1-\alpha)/(1-\alpha)]  .
\end{eqnarray*}
This is a little mysterious, but it's nice compact notation,
which is generally a good thing.

The risk penalty (\ref{eq:rp-def}) is therefore
\begin{eqnarray*}
    \rp &=& \log (\cbar/\mu)  \;\;=\;\; k(1) - (1-\alpha)^{-1} k(1-\alpha) .
\end{eqnarray*}
We see, for example, that it's zero when $\alpha = 0$:
someone who does not dislike risk has no risk penalty,
whatever that risk might be.
If we write down the expansion in terms of cumulants,
we can see the effects of individual cumulants:
\begin{eqnarray}
    \rp &=& k(1) - (1-\alpha)^{-1} k(1-\alpha) \nonumber \\
        &=& [1-(1-\alpha)] \kappa_2/2 + [1- (1-\alpha)^2] \kappa_3/3!
            + [1- (1-\alpha)^3] \kappa_4/4! + \cdots ,
        \label{eq:rp-cum-expansion}
\end{eqnarray}
where $\kappa_j$ is the $j$th cumulant of $x = \log c$.
If $\log c$ is normal (and $c$ lognormal), then only the first term appears,
the rest are zero.
The term says that the risk penalty is the product of risk aversion ($\alpha$)
and the variance over two ($\kappa_2/2$).

The other terms are more complicated.
They show the roles of high-order cumulants:  skewness, kurtosis, and so on.
In each coefficient, the one is simply the impact on the mean:
increasing any cumulant of $\log c$ raises the mean of $c$.
Beyond that, the magnitude of the impact of a cumulant
on the risk penalty depends on risk aversion $\alpha$ and risk $\kappa_j$.
We see that higher skewness ($\kappa_3$) reduces the risk penalty if $\alpha > 2$.
And so on.


\section*{Bottom line}

In risky environments, utility depends
on the complete set of consumption outcomes.
With expected utility, we divide that into separate components
for the probability and (sub)utility of each outcome.
Expected utility depends potentially on all of the moments and cumulants
of outcomes:
we need the whole distribution to assess risk.
Power utility is a particularly handy functional form
in which risk aversion is captured by a single parameter.
In this case, expected utility is closely connected to the
moment generating function for the log of consumption.

\section*{Practice problems}

\begin{enumerate}
\item {\it Lognormal risks.\/}
What is the {\it risk penalty\/} when consumption is lognormal
(the log of consumption is normal)?
To be concrete, let $x = \log c \sim \mathcal{N}(\kappa_1, \kappa_2)$
and $u(c) = c^{1-\alpha}/(1-\alpha)$ for $\alpha> 0$.

% ?? change to mgf -- also this one's a little hard
\begin{enumerate}
\item What is the moment generating function (mgf) of $x = \log c$?
\item Use the mgf to compute $\cbar = E(c) = E(e^x)$.
\item Use the mgf to compute expected utility $ E[u(c)]$.
\item What is the certainty equivalent $\mu$?
\item What is the risk penalty?  How does it depend on risk?  Risk aversion?
%\item Suppose $\kappa_2 = 0.02^2$.  What is the risk penalty if $\alpha = 2$?
%$\alpha = 10$?  $\alpha = 20$?
\end{enumerate}
%
\needspace{2\baselineskip}
Answer.
\begin{enumerate}
\item The mgf is (you should be getting used to this)
\begin{eqnarray*}
   h(s) &=&  E(e^{sx}) \;\;=\;\; \exp ( s \kappa_1 + s^2 \kappa_2/2 ).
\end{eqnarray*}
%The cgf is the log of this:
%$ %\begin{eqnarray*}
%    k(s) = \log h(s)  \;\;=\;\; s \kappa_1 + s^2 \kappa_2/2 $.
%%\end{eqnarray*}

\item The mean of $c$ is
$ \bar{c} = E(c) = E(e^x) = h(1) = e^{\kappa_1+\kappa_2/2}$.

\item Similarly, expected utility is
\begin{eqnarray*}
        E[u(c)] &=& E \Big(c^{1-\alpha}\Big)/(1-\alpha) \;\;=\;\; E \Big(e^{(1-\alpha) x}\Big)/(1-\alpha) \\
        &=& h(1-\alpha)/(1-\alpha) \;\;=\;\; e^{(1-\alpha)\kappa_1+(1-\alpha)^2\kappa_2/2}/(1-\alpha).
\end{eqnarray*}

\item The certainty equivalent is the consumption $\mu$ that gives the same utility,
namely $  u(\mu) = \mu^{1-\alpha}/(1-\alpha) = E[u(c)] $.
This implies
\begin{eqnarray*}
    \mu &=& \exp[ \kappa_1 + (1-\alpha) \kappa_2 /2 ] .
\end{eqnarray*}

\item The risk penalty is
\begin{eqnarray*}
    \log (\bar{c}/\mu) &=& \log \bar{c} - \log \mu \;\;=\;\; \alpha\kappa_2/2 ,
\end{eqnarray*}
which depends on risk (captured here by the variance $\kappa_2$)
and risk aversion ($\alpha$).
\end{enumerate}


\item {\it Risk aversion with upside risk.\/}
Consider a three-state distribution for your lifetime income.
The states occur with probabilities $(\omega, \omega, 1-2\omega)$
and involve lifetime annual incomes of $(100, 200, 1000)$.
We'll assume you consume your entire income every year.
We'll set $\omega = 0.495$, so that there's a one percent chance
of a big upside:  a lifetime income of a million a year.
The question is how large the impact is on your attitude toward income risk.
%
\begin{enumerate}
\item What is mean consumption?
\item If you have power utility with $\alpha = 3$, what is your certainty equivalent?
\item What is your risk penalty?
\item The question is how important the upside risk is to your risk penalty.
One way to approach this question is with the cumulant expansion
(\ref{eq:rp-cum-expansion}).
What is the first term in the expansion?
How does it compare to the total?
\end{enumerate}
%
\needspace{2\baselineskip}
Answer.
\begin{enumerate}
\item Mean consumption is 158.5.
\item Your certainty equivalent is 117.4.
\item Your risk penalty is $ \log (158.5/117.4) = 0.2999$.
\item The variance is $\kappa_2 = 0.1568$, so the first term
in the expansion is $\alpha \kappa_2 / 2 = 0.3920$.
See Matlab code below.
This tells us that the rest of the distribution --- the upside risk ---
lowers the risk penalty from 0.3920 (the variance term) to 0.2999 (the total).
What's going on?
Power utility agents like upside risk, including positive skewness,
even after we take into account its impact on the mean in the risk penalty.
\end{enumerate}

Matlab code:
\begin{verbatim}
% inputs
c = [100; 200; 1000];
omega = 0.5; %0.495;
p = [omega; omega; 1-2*omega];

% calculations
cbar = sum(p.*c)
alpha = 5;
mu = sum(p.*c.^(1-alpha)).^(1/(1-alpha))
rp = log(cbar/mu)

% cumulant expansion
kappa1 = sum(p.*log(c))
kappa2 = sum(p.*(log(c)-kappa1).^2)
varianceterm = alpha*kappa2/2
\end{verbatim}

\item {\it Exponential risks.\/}
Consider risk when when $x = - \log c $ is exponential,
a tractable nonnormal distribution.
The minus sign gives us negative skewness, which power utility agents
dislike.
The goal is to see how this shows up in the risk penalty.

The connection between $c$ and $x$ implies $c = e^{\log c} = e^{-x}$.
The pdf is
\begin{eqnarray*}
    p(x)  &=& \lambda e^{-\lambda x}
\end{eqnarray*}
for $x \geq 0$ and $\lambda > 0$.
The cgf is
\begin{eqnarray*}
    k(s)  &=& - \log \left( 1 - s/\lambda \right) .
\end{eqnarray*}
In terms of $x$, the mean of $c$ is $\bar{c} = E(c) = E (e^{-x})$.

\begin{enumerate}
\item Use the cgf to compute the variance, skewness, and excess kurtosis
of $x$.  How do they compare to those of the normal distribution?
\item Use the cgf to compute $\bar{c}$.
\item Choose the value of $\lambda$ that sets
the variance equal to $0.02^2$, the number we used earlier.
\item How does this differ from the lognormal example we did earlier?  Why?
\end{enumerate}
%
\needspace{2\baselineskip}
Answer.
\begin{enumerate}
\item The first four cumulants are
$\kappa_1 = 1/\lambda$,
$\kappa_2 = 1/\lambda^2$,
$\kappa_3 = 2/\lambda^3$,
and $\kappa_4 = 6/\lambda^4$.
Skewness and excess kurtosis are therefore
$\gamma_1 = 2$ and $\gamma_2 = 6$.

\item If $k(s)$ is the cgf of $x$,
then $\log \bar{c} = k(-1)$ ($k$ evaluated at $s=-1$):
$k(-1) = - \log (1 + 1/\lambda)$.

\item We solve $0.02^2 = 1/\lambda^2$ or $\lambda = 1/0.02 = 50$.

\item The risk penalties are
%
\begin{center}
\begin{tabular}{lccc}
\toprule
        & $\alpha=2$  & $\alpha=10$  & $\alpha=20$ \\
\midrule
lognormal    &  0.0004 & 0.0020 & 0.0040 \\
exponential  &  0.0004 & 0.0022 & 0.0054 \\
\bottomrule
\end{tabular}
\end{center}
%
The point is that departures from normality matter, although they're not
especially large here.
The numbers suggest that the impact increases with risk aversion $\alpha$.
This may seem mysterious now,
but we could elaborate using the power series expansion of the risk penalty.
Amir Yaron (Wharton prof) refers to this as a ``bazooka,''
since it allows you to take a little nonnormality
and generate enormous risk premiums.
More on this kind of thing later in the course.
\end{enumerate}



\item {\it Exponential utility.\/}
Another common utility function is $u(c) = -\alpha^{-1} e^{-\alpha c} $,
with $\alpha > 0$.
It's a convenient functional form for evaluating attitudes toward risk.
We'll combine this with a Poisson distribution for consumption:
$c = \delta z$ with probability $ \omega^z e^{-\omega} /z!$ for $z = 0, 1, 2, \ldots $
and $\omega,\delta > 0$.
\begin{enumerate}
\item Verify that utility $u$ is increasing and concave.
\item What is the mgf of $c$?  What is mean consumption?
\item Use the mgf to compute expected utility.
\item What is the certainty equivalent $\mu$?
\item What is the risk penalty?
\end{enumerate}
%
\needspace{2\baselineskip}
Answer.
\begin{enumerate}
\item The first two derivatives are
\begin{eqnarray*}
    u'(c) &=& e^{-\alpha c} \;\;>\;\; 0 \\
    u''(c) &=& -\alpha e^{-\alpha c} \;\;<\;\; 0 .
\end{eqnarray*}

\item The mgf is (see the notes on random variables)
\begin{eqnarray*}
    h(s) \;\;=\;\;  E(e^{sc}) &=& E(e^{s\delta z}) \;\;=\;\;  e^{\omega (e^{\delta s} -1)} .
\end{eqnarray*}
The mean is $ E(c) = \omega\delta $.

\item Expected utility is
\begin{eqnarray*}
 - \alpha^{-1} E(e^{-\alpha c}) &=& - \alpha^{-1} h(-\alpha)
            \;\;=\;\; - \alpha^{-1} e^{\omega (e^{-\delta\alpha } -1)} .
\end{eqnarray*}

\item The certainty equivalent solves $u(\mu) = E[u(c)]$, which here implies
\begin{eqnarray*}
    \mu &=& \alpha^{-1} \omega (1- e^{-\delta \alpha}) .
\end{eqnarray*}

\item The risk penalty is
\begin{eqnarray*}
    \rp &=& \log [E(c)/\mu]
            \;\;=\;\; \log (\delta \alpha) - \log (1- e^{-\delta \alpha}) .
\end{eqnarray*}
The point is that we have a combination of risk and risk aversion,
but it's not nearly as simple as in the lognormal case.
In a sense, the lognormal case misleads us into thinking this will be simple.
\end{enumerate}

% ?? \item {\it Gamma risks.  (or normal mixture?).\/}


\end{enumerate}



\vfill \centerline{\it \copyright \ \number\year \
NYU Stern School of Business}


\end{document}

NOTES
********************************
Samuelson reference

Samuelson REStud 1970
http://www.jstor.org/stable/2296483

Related
http://www.jstor.org/pss/1827501
http://www.jstor.org/pss/2118079
http://www.rhsmith.umd.edu/faculty/gskoulak/Taylor_Approximation_Quality_CRRA.pdf
http://finance.sauder.ubc.ca/~garlappi/Papers/Taylor_GS_2009_08_28.pdf
