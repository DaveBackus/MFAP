\documentclass[11pt]{exam}

\oddsidemargin=0.25truein \evensidemargin=0.25truein
\topmargin=-0.5truein \textwidth=6.0truein \textheight=8.75truein

%\RequirePackage{graphicx}
\usepackage{comment}
\usepackage{verbatim} 
\usepackage[dvipdfm]{hyperref}
\urlstyle{rm}   % change fonts for url's (from Chad Jones)
\hypersetup{
    colorlinks=true,        % kills boxes
    allcolors=blue,
    pdfsubject={ECON-UB233, Macroeconomic foundations for asset pricing},
    pdfauthor={Dave Backus @ NYU},
    pdfstartview={FitH},
    pdfpagemode={UseNone},
%    pdfnewwindow=true,      % links in new window
%    linkcolor=blue,         % color of internal links
%    citecolor=blue,         % color of links to bibliography
%    filecolor=blue,         % color of file links
%    urlcolor=blue           % color of external links
% see:  http://www.tug.org/applications/hyperref/manual.html
}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\newcommand{\var}{\mbox{\it Var\/}}

%\noprintanswers
\printanswers

% document starts here
\begin{document}
\parskip=\bigskipamount
\parindent=0.0in
\thispagestyle{empty}
{\large ECON-UB 233 \hfill Dave Backus @ NYU}

\bigskip\bigskip
\centerline{\Large \bf Lab Report \#1: Moments \& Cumulants}
\centerline{(Started: July 19, 2011; Revised: \today)}

\bigskip
{\it Due at the start of class.
You may speak to others, but whatever you hand in should be your own work.}

\begin{questions}

\begin{solution}
The solutions to this assignment are computed in the Matlab
program listed at the end and posted
\href{http://pages.stern.nyu.edu/~dbackus/233/hw1_s12.m}{here}.
If you run the program yourself,
the output will give you most of what's asked for.
The answers below go beyond this.
\end{solution}

%-----------------------------------------------------------------------
\question (cumulants of Bernoulli random variables)
Consider a random variable $x$ that equals
$\delta$ (an arbitrary number) with probability $p$ (a number between zero and one)
and $0$ with probability $1-p$.
We'll use its cumulant generating function (cgf)
to find its first four cumulants, representing,
respectively, its mean, variance, skewness, and kurtosis.
Feel free to use Matlab --- I would.
%
\begin{parts}
\part Verify that this is a legitimate probability distribution.

\part Derive the moment generating function.
(If you're confused about this, apply the definition.)
What is the cumulant generating function?

\part Differentiate the cgf to find the
first four cumulants, labelled $\kappa_1$ through $\kappa_4$.

\part Derive the standard measures of skewness and excess kurtosis:
\begin{eqnarray*}
    \gamma_1 &=&  \kappa_3 /(\kappa_2)^{3/2}  \;\; \mbox{(skewness)} \\
    \gamma_2 &=&  \kappa_4 /(\kappa_2)^{2}    \;\;\;\;\; \mbox{(excess kurtosis)}
\end{eqnarray*}
How do they depend on $p$?  $\delta$?
What is excess kurtosis when $p=1/2$?
\end{parts}

\begin{solution}
This the Bernoulli multiplied by $\delta$, so it illustrates the
impact (or lack thereof) of scaling.
\begin{parts}
\part Since $p$ and $1-p$ are nonnegative and sum to one, we're ok.
\part See program.
\part The cumulants are
\begin{eqnarray*}
    \kappa_1 &=& \delta p \\
    \kappa_2 &=& \delta^2 p (1-p) \\
    \kappa_3 &=& \delta^3 p (1-p) (1-2p) \\
    \kappa_4 &=& \delta^4 p (1-p) [ 1 - 6 p (1-p)] .
\end{eqnarray*}
Note the scaling:  $\kappa_j$ includes $\delta^j$.
Other than scaling, we've seen the first two before.
The third one tells us that skewness depends on the sign of $\delta$
and whether $p$ is greater or less than one half
(graph the probabilities against $x$ if this isn't clear).
The fourth one depends on $p(1-p)$.
At $p=1/2$, this terms reaches its max of 1/4,
so the overall term is negative, which generates negative excess kurtosis.
As $p$ moves toward zero or one, this term shrinks.
\part
You'll note that Matlab doesn't do the obvious cancelation of $\delta$'s.
Once you do, you have
\begin{eqnarray*}
    \gamma_1 &=& \mbox{sgn} (\delta) (1-2p)/[ p (1-p)]^{1/2} \\
    \gamma_2 &=& 1/[p (1-p)] - 6 .
\end{eqnarray*}
There's a subtle issue with $\gamma_1$:
the magnitude of $\delta$ doesn't matter, but it's sign (``sgn'') does.
That shows up in the ratio of $[\delta^2]^{3/2}$ to $\delta^3$
(think about this a minute).
What about excess kurtosis?
At $p = 1/2$, $\gamma_2=-2$, so there's excess kurtosis.
Loosely speaking, the Bernoulli has thin tails (very thin).
As $p$ approaches zero or one, we can reverse that.
We're getting in this case a distribution with increasing skewness
and excess kurtosis.
\end{parts}
\end{solution}

%-----------------------------------------------------------------------
\question (sample moments)
It's often helpful to experiment with artificial test problems,
so that we know when we make a mistake.
Here we compute sample moments of data generated by the computer
and verify what we think they are.

We'll start by generating some artificial data:
\begin{verbatim}
format compact
mu = 0;
sigma = 1;
nobs = 1000;
x = normrnd(mu,sigma,nobs,1);
\end{verbatim}
These commands generate ``pseudo-random'' numbers from a
normal distribution and put them in the vector $x$.
The serve as data for what follows.

\begin{parts}

\part Our first check is to see if the sample moments
correspond, at least approximately,
to our knowledge of normal random variables.
For example, use the commands:
\begin{verbatim}
xbar = mean(x)
moments = mean([(x-xbar).^2 (x-xbar).^3 (x-xbar).^4])
\end{verbatim}
What do you get?
What are the first four sample moments?
What are the moments of a normal random variable
with this mean and variance?
How do they compare?

\part Our second check is on the Matlab commands
{\tt mean(x)}, {\tt std(x)}, {\tt skewness(x)}, and {\tt kurtosis(x)}.
How do they compare to sample moments you computed earlier?
Are they exactly the same, almost the same, or completely different?
\end{parts}

\begin{solution}
\begin{parts}
\part The moments are close to what the distribution implies:
mean one, variance (and standard deviation) one,
skewness zero, and kurtosis three.
The small differences reflect sampling variability.
You can see this by increasing the sample size,
which typically leads the sample moments to be closer
to the ``population'' moments.
The one difference is in the variance and standard
deviation, which are computed by dividing the
sum of squared deviations by the number of observations minus one,
rather than just the number of observations.
It's a small difference, to be sure.

\item The {\tt skewness} and {\tt kurtosis} commands
give exactly the same answers as our own calculations,
which assures us that they do what we want them to do.
\end{parts}
\end{solution}

%-----------------------------------------------------------------------
\question (volatility and correlation in business cycles)
We're going to use macroeconomic data from FRED,
the St Louis Fed's convenient online data repository,
to get a summary picture of US business cycles.
(Search ``FRED St Louis''.)
%
Data preparation should follow these steps or the equivalent:
\begin{itemize}
\item Download monthly data, 1960 to the present,
for the following series:
Industrial Production (series INDPRO),
Employment (All Employees: Total Nonfarm, series PAYEMS),
Real Personal Consumption Expenditures (PCEPI),
and the S\&P 500 Index (SP500).
GDP is not available monthly, so the first three series serve as alternative
measures of economic activity.
Variation in their growth rates reflects the business cycle.
The last one serves as our measure of asset prices,
and its growth rate as the (approximate) return on equity.
Save them all in a spreadsheet, with each series in its own column.

\item Read your data into Matlab and construct year-on-year growth rates
using the formula
\begin{eqnarray*}
    g_{t} &=& \log x_t - \log x_{t-12} .
\end{eqnarray*}
[The function {\tt log} here is the natural log.
We refer to growth rates computed this way as continuously-compounded.
Take that as given for now,
but ask me in class if you'd like an explanation.]
If the data are in an array called {\tt data}, with each column a different variable,
you can compute growth rates with
\begin{verbatim}
diffdata = log(data(13:end,:)) - log(data(1:end-12,:))
\end{verbatim}
[The expressions {\tt data(i,j)} have two forms here.
The first index is a range (eg, {\tt x:y}), where
{\tt end} means the last one.
The second index ({\tt :}) means use all the available columns.]

\item A short-cut for the adventurous.
I don't recommend this
unless you're fairly comfortable with Matlab,
and maybe not even then,
but my colleague Kim Ruhl has written a script that automates
data input from FRED; that is, you can skip the spreadsheet step.
If you'd like to try it, see

\medskip
\centerline{\url{http://www.kimjruhl.com/computing/}.}
\end{itemize}
%
Once you have the data ready to go:
%
\begin{parts}
\part For each variable (that is, its growth rate),
compute the standard deviation,
skewness, and excess kurtosis.
(The commands {\tt std}, {\tt skewness}, and {\tt kurtosis}
are helpful here.)
Which variables have the highest ``volatility'' (standard deviation)?
Do any of them seem ``nonnormal'' to you?

\part For the same variables, compute correlations with employment growth.
(The command {\tt corrcoef} may come in handy.)
Which variable has the highest correlation?
\end{parts}

\begin{solution}
See the Matlab program.
Note that there's negative skewness in most of these series,
also positive excess kurtosis.
The outlier here is consumption --- I may have to check into that.
Industrial production and employment are highly correlated
(above 0.8), the S\&P 500 less so (correlation about 0.3 with
the former, 0.15 with the latter).

I recommend, in addition, that you plot the series and look at their
histograms.
\end{solution}

%-----------------------------------------------------------------------
\question {\bf Optional.} (sum of normals is normal)
The idea here is to use cumulant generating functions (cgfs)
to show that the sum of independent normal random variables is also normal.
It's helpful to break the problem into manageable pieces, like this:
\begin{parts}
\part Consider two independent random variables $x_1$ and $x_2$,
    not necessarily normal.
    Show that the cgf of the sum $y = x_1 + x_2$ is the sum of their cgfs:
\begin{eqnarray*}
	k(s; y) &=& k(s; x_1) + k(s;x_2) .
\end{eqnarray*}
Hint:  note the form of the pdf and apply the definition of the cgf.

\part Suppose $x_i \sim \mathcal{N}(\kappa_{i1}, \kappa_{i2})$.
[This bit of notation means:   $x_i$ is normally distributed with
mean $\kappa_{i1}$ and variance $\kappa_{i2}$.]
What is $x_i$'s cgf?
Hint:  we did this in class.

\part Use (a) to find the cgf of $y = x_1 + x_2$,
with $(x_1,x_2)$ as described in (b) (namely, normal with given means and variances).
How do you know that $y$ is also normal?  What are its mean and variance?

\part Extend this result to $y = a x_1 + b x_2$ for any real numbers $(a,b)$.
\end{parts}

\begin{solution}
\begin{parts}
\part If $x_1$ and $x_2$ are independent, they're pdf factors:
$ p_{12}(x_1,x_2) = p_1(x_1) p_2(x_2) $.
That means the mgf of $x_1+x_2$ is the product of their individual mgf's
and their cgf is the sum.
\part $  k(s; x_i) = s \kappa_{1i} + s^2 \kappa_{2i}/2 $.
(If this isn't burned into your memory, please burn it now.)
\part Sum the cgf's:
\begin{eqnarray*}
    k(s; y) &=& k(s,x_1) + k(s,x_2) \\
            &=& (s \kappa_{11} + s^2 \kappa_{21}/2) + (s\kappa_{12} + s^2 \kappa_{22}/2) \\
            &=& s (\kappa_{11} + \kappa_{12} )
                + s^2 (\kappa_{21} + \kappa_{22}) .
\end{eqnarray*}
It's normal because it's mgf has the form of a normal random variable.
\part Still normal, but with a slight change in mean and variance:
\begin{eqnarray*}
    k(s; y) &=& s (a \kappa_{11} + b \kappa_{12} )
                + s^2 (a^2 \kappa_{21} + b^2 \kappa_{22}) .
\end{eqnarray*}
\end{parts}
\end{solution}

\end{questions}

Matlab program for questions 1 to 3: \\
\verbatiminput

\end{document}



